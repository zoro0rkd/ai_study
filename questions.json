[
  {
    "type": "objective",
    "number": 1,
    "question": "AI 분야에서 머신러닝과 딥러닝의 주요 차이점은 무엇인가?",
    "choices": [
      "모델 크기",
      "데이터 양",
      "신경망의 유무",
      "학습 속도",
      "정확도"
    ],
    "textboxCount": 0
  },
  {
    "type": "subjective",
    "number": 2,
    "question": "보기에 알맞은 단어는?",
    "explanation": "A)는 기계 학습 분야의 한 방법으로, 모델이 훈련 중에 본 적 없는 데이터나 클래스에 대해\n예측을 수행할 수 있도록 하는 기술이다. 이 기법은 특히 데이터 레이블링 비용이 많이 들거나,\n실제 환경에서 예측해야 할 클래스가 훈련 데이터에 모두 포함되지 않는 경우에 유용하다.\n최근에는 (A)의 확장된 형태인 Generalized (A)를 활용하는 방법이 주목받고 있다. 이 방법은\n모델이 훈련 중에 본 적 있는 클래스와 본 적 없는 클래스를 동시에 인식할 수 있도록 설계된\n기법이다. Generalized (A)는 더욱 실용적인 시나리오에서의 활용성을 고려하여 개발되었으며,\n실제 환경의 응용에서 더욱 현실적인 문제를 해결하는데 도움을 준다.",
    "textboxCount": 2
  },
  {
    "type": "essay",
    "number": 3,
    "question": "AI 기술 발전이 사회 구조에 미치는 영향에 대해 서술하시오.",
    "choices": [],
    "textboxCount": 1
  },
  {
    "type": "objective",
    "number": 4,
    "question": "다음 설명에 해당하는 AI 기술은 무엇인가?",
    "explanation": "images/Q4.png",
    "choices": [
      "Zero-Shot Learning",
      "Transfer Learning",
      "Reinforcement Learning",
      "Unsupervised Learning",
      "Few-Shot Learning"
    ],
    "textboxCount": 0
  },
  {
    "type": "subjective",
    "number": 11,
    "question": "다음 문단은 앙상블 및 모델 결합 전략을 설명한 것이다. 괄호 (A) ~ (C) 에 들어갈 알맞은 용어를 〈보기〉에서 골라 순서대로 각각 쓰시오.",
    "choices": [],
    "explanation": "모델의 일반화 성능을 향상하고 편차와 분산을 동시에 완화하려면, 여러 개 모델을 조합하는 앙상블 접근이 효과적이다. 먼저 (A) 은/는 훈련 데이터를 여러 부트스트랩 샘플로 나눠 각각의 독립 모델을 학습한 뒤 평균이나 다수결로 예측을 통합해 분산을 줄인다. 반대로 (B) 은/는 이전 모델이 놓친 “어려운” 샘플에 가중치를 더해 모델을 순차적으로 학습함으로써 편차를 축소한다. 한편 (C) 은/는 여러 기본 학습기의 출력을 메타-모델의 입력으로 사용해 비선형 방식으로 조합, 개별 모델보다 높은 표현력을 얻는다.\n〈보기〉\n ㄱ. Random Subspace Method\n ㄴ. Boosting\n ㄷ. Voting Ensemble\n ㄹ. Snapshot Ensemble\n ㅁ. Knowledge Distillation\n ㅂ. Stacking\n ㅅ. Blending\n ㅇ. Bayesian Model Averaging\n ㅈ. Bagging",
    "textboxCount": 3
  },
  {
    "type": "objective",
    "number": 12,
    "question": "딥러닝 모델을 훈련할 때 GPU 메모리가 초과(OOM)되는 상황을 줄이기 위해 고안된 아키텍처 설계/훈련 전략에 관한 다음 설명을 읽고, 옳은 것만을 모두 고르시오.",
    "explanation": "ㄱ.  Reversible Residual Layer (예: Reformer, RevNet)을 사용하면 순전파 단계의 모든 중간 활성값을 저장할 필요가 없으므로,  활성 메모리 사용량 을 크게 줄여 OOM을 완화할 수 있다. \nㄴ.Transformer의 Feed-Forward Network(FFN) 은닉 차원을 2 배 이상 키우면, 동일 배치 크기에서 필요한 TPU/GPU 메모리가 감소해 OOM 위험이 줄어든다.\nㄷ. Linformer 는 Self-Attention 행렬을 저차원(k)으로 근사해 O(n^2)이던 메모리·연산량을 O(nk)로 낮추므로,  초장문(long sequence) 학습 시  메모리 폭증 문제를 완화한다.\nㄹ. Zero Redundancy Optimizer (ZeRO)  Stage-2는 파라미터와 옵티마이저 상태를 각 GPU에  중복  저장하므로, 장치별 메모리 사용량이 오히려 증가해 OOM을 악화시킨다.",
    "choices": [
      "ㄱ,ㄴ",
      "ㄱ,ㄷ",
      "ㄴ,ㄷ",
      "ㄱ,ㄷ,ㄹ",
      "ㄱ,ㄴ,ㄹ"
    ],
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 13,
    "question": "다음은 모델 투명성 관련 개념을 서술한 것이다. 이 중 설명 가능성(Explainability)에 해당하는 내용만을 모두 고른 것은?",
    "explanation": "ㄱ. 깊이가 얕은 의사결정나무(decision tree)는 분기 경로를 그대로 확인할 수 있어 모델 동작을 수학적으로 투명하게 해 준다.\nㄴ. LIME·SHAP 기법은 각 입력 특성이 예측에 기여한 정도를 수치·시각으로 제시해 사용자가 “왜 이런 결과가 나왔는지”를 이해하도록 돕는다.\nㄷ. 희소(sparse) 선형 모델은 계수를 직접 열람할 수 있으므로 전역 수준에서 특성-가중치 관계를 해석하기 쉽다.\nㄹ. Counterfactual Explanation은 출력이 바뀌도록 입력을 최소한으로 수정한 예시를 제시해, 사용자가 결정을 바꿀 ‘행동 가능’ 단서를 제공한다.",
    "choices": [
      "ㄱ,ㄴ",
      "ㄱ,ㄷ",
      "ㄴ,ㄷ",
      "ㄴ,ㄹ",
      "ㄱ,ㄴ,ㄹ"
    ],
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 14,
    "question": "다음은 그림은 NLP 모델을 설명 가능하게 분석하는 방법 중 하나이다.<보기> 중 해당 모델에 대한 설명으로 옳은 것을 모두 고른것은?",
    "explanation": "images/Q14.png",
    "choices": [
      "ㄱ,ㄴ",
      "ㄱ,ㄷ",
      "ㄴ,ㄷ",
      "ㄱ,ㄷ,ㄹ",
      "ㄱ,ㄴ,ㄹ"
    ],
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 15,
    "question": "다음은 여러 번 데이터셋을 나누어 모델을 학습‧평가하는 방법에 대한 설명이다. 옳은 설명만을 모두 고르시오.",
    "explanation": "images/Q15.png",
    "choices": [
      "ㄱ,ㄴ",
      "ㄱ,ㅁ",
      "ㄴ,ㄷ",
      "ㄹ,ㅁ",
      "ㄱ,ㄴ,ㅁ"
    ],
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 16,
    "question": "[AI 모델 학습 및 평가] 다음은 AI 모델 학습 및 평가에 관련된 설명이다. 옳은 설명을 모두 고른 것을 고르시오.",
    "choices": [
      "ㄱ, ㄴ",
      "ㄱ, ㄷ, ㄹ",
      "ㄱ, ㄷ, ㅁ",
      "ㄱ, ㄴ, ㄷ, ㄹ",
      "ㄷ, ㄹ, ㅁ"
    ],
    "explanation": "<보기>\nㄱ. 과적합을 방지하기 위해 정규화 기법 중 하나인 Dropout을 적용할 수 있다. \nㄴ. F1-score는 Precision과 Recall의 산술 평균으로 계산된다. \nㄷ. Gradient Clipping은 기울기 폭주 문제를 해결하는 데 사용된다. \nㄹ. Cross-validation은 전체 데이터를 여러 개의 조각으로 나누어 반복적으로 학습 및 평가하는 방식이다. \nㅁ. AUC 값이 0.5에 가까울수록 모델의 분류 성능이 우수함을 의미한다.",
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 17,
    "question": "[AI 모델 학습 및 평가] 다음은 분류 모델의 성능 평가를 위한 지표이다. 보안 시스템에서 실제 침입자를 놓치지 않는 것이 가장 중요한 경우, 다음 중 가장 적절한 평가 지표는 무엇인가?",
    "choices": [
      "정확도(Accuracy)",
      "정밀도(Precision)",
      "재현율(Recall)",
      "F1 점수(F1 Score)"
    ],
    "textboxCount": 0
  },
  {
    "type": "essay",
    "number": 18,
    "question": "딥러닝 모델이 훈련 데이터에는 높은 성능을 보이지만, 새로운 데이터에서는 예측 정확도가 급격히 저하되는 현상이 발생할 수 있다. 이러한 상황을 방지하거나 개선하기 위해 사용되는 세 가지 대표적인 학습 기법 또는 전략을 기술하고, 각 기법의 핵심 원리와 모델에 미치는 긍정적 영향을 간단히 설명하시오.",
    "choices": [],
    "textboxCount": 1
  },
  {
    "type": "objective",
    "number": 19,
    "question": "[AI 모델 튜닝] (A) - (B) - (C)에 들어갈 가장 적절한 용어의 조합을 고르시오.",
    "choices": [
      "ㄱ - ㄴ - ㄷ",
      "ㄱ - ㄷ - ㄴ",
      "ㄴ - ㄱ - ㄷ",
      "ㄷ - ㄴ - ㄱ",
      "ㄴ - ㄷ - ㄱ"
    ],
    "explanation": "딥러닝 모델의 성능을 높이기 위해 하이퍼파라미터 튜닝은 매우 중요한 작업이다. 튜닝을 자동화하기 위한 다양한 기법이 존재하며, 그 중 (A)은 가능한 모든 하이퍼파라미터 조합을 시도하는 방식으로, 간단하지만 비효율적일 수 있다. (B)는 하이퍼파라미터 조합을 무작위로 선택하는 방법으로, 자원이 제한된 상황에서 특정 조합을 빠르게 찾을 수 있다. 최근에는 (C)처럼 이전 실험 결과를 바탕으로 다음 실험을 더 효과적으로 설계하는 기법이 주목받고 있다. \n<보기>\nㄱ) Grid Search \nㄴ) Random Search \nㄷ) Bayesian Optimization \nㄹ) Learning Rate Warmup \nㅁ) Gradient Clipping",
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 20,
    "question": "[AI 모델 튜닝] 딥러닝 모델의 하이퍼파라미터 중 학습률(learning rate)에 대한 설명으로 가장 적절한 것을 고르시오.",
    "choices": [
      "학습률이 너무 높으면 손실 함수의 지역 최솟값에 빠질 위험이 높아진다.",
      "학습률이 너무 낮으면 모델이 빠르게 수렴하고 과적합이 발생할 수 있다.",
      "학습률이 너무 높으면 손실 함수가 발산하거나 수렴하지 않을 수 있다.",
      "학습률은 일반적으로 고정된 값으로 설정하며, 학습 도중에 변경해서는 안 된다."
    ],
    "textboxCount": 0
  },
  {
    "type": "subjective",
    "number": 21,
    "question": "보기에 알맞은 단어는?",
    "explanation": "(A)는 AI 모델을 웹 애플리케이션 내부에 내장하여 함께 배포하는 방식이며, 모델이 웹 서버 내에서 직접 실행된다. 반면, (B)는 모델을 별도의 서버 또는 컨테이너에 분리하여 배포하고, API를 통해 호출하는 방식이다. (B)는 모델과 서비스의 독립적 운영이 가능하며, 유지보수 및 확장성 측면에서 유리하다.",
    "textboxCount": 2
  },
  {
    "type": "objective",
    "number": 22,
    "question": "[AI 시스템 구축 및 배포] (가) - (나) - (다)에 들어갈 가장 적절한 설명 조합을 고르시오.",
    "choices": [
    "ㄱ. (가): 데이터 전처리 / (나): 모델 학습 / (다): 모델 패키징",
    "ㄴ. (가): 모델 학습 / (나): 데이터 수집 / (다): 모델 서빙",
    "ㄷ. (가): 모델 서빙 / (나): 데이터 전처리 / (다): 모델 학습",
    "ㄹ. (가): 모델 패키징 / (나): 모델 학습 / (다): 모델 모니터링",
    "ㅁ. (가): 데이터 정제 / (나): 하이퍼파라미터 튜닝 / (다): 모델 배포"
  ],
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 23,
    "question": "다음 중 경량화 기법과 직접적인 관련이 가장 적은 조합을 고르시오.",
    "choices": [
      "① Depthwise Separable Convolution － 연산량 감소",
      "② Knowledge Distillation － 학생-교사 구조",
      "③ Label Smoothing － 매개변수 수 축소",
      "④ Quantization － 정수 연산 활용",
      "⑤ Structured Pruning － 채널 단위 가중치 제거"
    ],
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 24,
    "question": "Retrieval-Augmented Generation (RAG) 파이프라인의 주요 구성 요소에 해당하지 않는 것은?",
    "choices": [
      "① 외부 지식베이스를 인덱싱하는 임베딩 파이프라인",
      "② 밀집 벡터 간 유사도 검색을 수행하는 Retriever",
      "③ 원문을 LLM 입력에 삽입하는 Context Assembler",
      "④ 생성 결과의 사실성을 검증하기 위한 Post-hoc Fact-Checker",
      "⑤ 사전 훈련 단계에서 매개변수 효율을 높이기 위한 LoRA Adaptor"
    ],
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 25,
    "question": "멀티모달 LLM 학습 접근법 (가)와 (나)를 <보기>와 올바르게 짝지은 것을 고르시오.\n\n(가) Vision Encoder와 Text Decoder를 결합해 이미지→텍스트 생성 능력을 강조한다.\n(나) Cross-attention 레이어를 다중 모달 입력 사이에 삽입해 동시 추론을 수행한다.\n\n<보기>\nA. Autoregressive Image Captioning\nB. Contrastive Language-Image Pre-training(CLIP)\nC. Multimodal Fusion Transformer\nD. Diffusion-based Latent Blending",
    "choices": [
      "① (가)-A (나)-C",
      "② (가)-B (나)-A",
      "③ (가)-C (나)-B",
      "④ (가)-D (나)-A",
      "⑤ (가)-B (나)-D"
    ],
    "textboxCount": 0
  }
]
