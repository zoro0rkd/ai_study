[
    {
      "type": "objective",
      "number": 1,
      "question": "AI 분야에서 머신러닝과 딥러닝의 주요 차이점은 무엇인가?",
      "choices": [
        "모델 크기",
        "데이터 양",
        "신경망의 유무",
        "학습 속도",
        "정확도"
      ],
      "textboxCount": 0
    },
    {
      "type": "subjective",
      "number": 2,
      "question": "보기에 알맞은 단어는?",
      "explanation": "A)는 기계 학습 분야의 한 방법으로, 모델이 훈련 중에 본 적 없는 데이터나 클래스에 대해\n예측을 수행할 수 있도록 하는 기술이다. 이 기법은 특히 데이터 레이블링 비용이 많이 들거나,\n실제 환경에서 예측해야 할 클래스가 훈련 데이터에 모두 포함되지 않는 경우에 유용하다.\n최근에는 (A)의 확장된 형태인 Generalized (A)를 활용하는 방법이 주목받고 있다. 이 방법은\n모델이 훈련 중에 본 적 있는 클래스와 본 적 없는 클래스를 동시에 인식할 수 있도록 설계된\n기법이다. Generalized (A)는 더욱 실용적인 시나리오에서의 활용성을 고려하여 개발되었으며,\n실제 환경의 응용에서 더욱 현실적인 문제를 해결하는데 도움을 준다.",
      "textboxCount": 2
    },
    {
      "type": "essay",
      "number": 3,
      "question": "AI 기술 발전이 사회 구조에 미치는 영향에 대해 서술하시오.",
      "choices": [],
      "textboxCount": 1
    },
    {
      "type": "objective",
      "number": 4,
      "question": "다음 설명에 해당하는 AI 기술은 무엇인가?",
      "explanation": "images/Q4.png",
      "choices": [
        "Zero-Shot Learning",
        "Transfer Learning",
        "Reinforcement Learning",
        "Unsupervised Learning",
        "Few-Shot Learning"
      ],
      "textboxCount": 0
    },
    {
      "type": "subjective",
      "number": 11,
      "question": "아래 그림은 어떤 네트워크의 구조를 나타낸 것이다. 그림을 참고하여 Residual Connection의 주된 역할을 영어로 작성하시오.",
      "explanation": "images/Q11.png",
      "choices": [
      ],
      "textboxCount": 1
    },
    {
      "type": "objective",
      "number": 12,
      "question": "Transformer 인코더 블록의 주요 구성 요소가 아닌 것을 고르시오.",
      "explanation": "",
      "choices": [
        "Multi-Head Attention",
        "Position-wise Feed-Forward Network",
        "Layer Normalization",
        "Positional Encoding",
        "Convolutional Layer"
      ],
      "textboxCount": 0
    },
    {
      "type": "objective",
      "number": 13,
      "question": "다음 중 Surrogate Model의 설명으로 가장 적절한 것은?",
      "explanation": "ㄱ. 원래 모델의 입력과 출력 간의 복잡한 관계를 근사하기 위해 단순 모델을 학습한다.\nㄴ. Surrogate Model은 항상 딥러닝 기반 모델로 설계된다.\nㄷ. 주로 모델의 해석 가능성(interpretability) 향상을 위해 사용된다.\nㄹ. Surrogate Model은 실제 모델의 성능(accuracy)을 직접 향상시키기 위해 훈련된다.\nㅁ. 선형 회귀, 의사결정나무 등 해석 가능한 모델이 사용될 수 있다.",
      "choices": [
        "ㄱ,ㄴ",
        "ㄷ,ㄹ",
        "ㄷ,ㅁ",
        "ㄱ,ㄴ,ㅁ",
        "ㄱ,ㄷ,ㅁ"
      ],
      "textboxCount": 0
    },
    {
      "type": "objective",
      "number": 14,
      "question": "아래 그림에서 제안한 기법의 제약 사항으로 옳지 않은 것은?",
      "explanation": "images/Q14.png",
      "choices": [
        "특징맵의 중요도는 모델의 손실함수 그래디언트가 아닌 완전연결 계층의 가중치로 산출된다.",
        "모델 예측 시 Global Average Pooling(GAP) 레이어 이전의 특징맵만을 사용한다.",
        "다양한 계층의 특징맵으로도 자유롭게 Class Activation Map을 생성할 수 있다.",
        "입력 영상에서 분류 대상 객체의 위치 정보를 시각화한다.",
        "CNN 기반 분류 모델에 특화된 모델-특정(Model-specific) XAI 기법이다."
      ],
      "textboxCount": 0
    },
    {
      "type": "objective",
      "number": 15,
      "question": "다음 중 클래스 불균형이 심한 이진 분류 문제에서 Precision과 Recall의 조화를 가장 잘 나타내는 지표는?",
      "explanation": "",
      "choices": [
        "Accuracy",
        "Precision",
        "Recall",
        "F1-Score",
        "ROC AUC"
      ],
      "textboxCount": 0
    },
    {
      "type": "objective",
      "number": 16,
      "question": "[AI 모델 학습 및 평가] 딥러닝 모델 학습시 과적합(overfitting) 현상이 발생했다고 판단할 때, 이를 방지하기 위한 적절한 조치로 알맞은 것을 모두 고른 것은?",
      "choices": [
        "ㄱ, ㄷ",
        "ㄴ, ㄷ",
        "ㄱ, ㄴ",
        "ㄱ, ㄹ",
        "ㄴ, ㄹ"
      ],
      "explanation": "<보기>\n ㄱ. 학습 데이터의 수를 증가시킨다\n ㄴ. L2 정규화를 도입하여 가중치 크기를 제한한다\n ㄷ. 모델의 파라미터 수를 늘려 복잡도를 증가시킨다\n ㄹ. Dropout 레이어를 추가하여 일부 뉴런을 무작위로 비활성화한다",
      "textboxCount": 0
    },
    {
      "type": "objective",
      "number": 17,
      "question": "[AI 모델 학습 및 평가] 다음은 분류 모델의 성능 평가를 위한 지표이다. 보안 시스템에서 실제 침입자를 놓치지 않는 것이 가장 중요한 경우, 다음 중 가장 적절한 평가 지표는 무엇인가?",
      "choices": [
        "정확도(Accuracy)",
        "정밀도(Precision)",
        "재현율(Recall)",
        "F1 점수(F1 Score)"
      ],
      "textboxCount": 0
    },
    {
      "type": "essay",
      "number": 18,
      "question": "AI 모델을 학습할 때, 과적합(overfitting) 과 과소적합(underfitting) 은 모두 성능 저하의 원인이 된다. 과적합과 과소적합의 차이를 설명하고, 각각의 상황에서 어떤 해결 방법을 적용할 수 있는지 서술하시오.",
      "choices": [],
      "textboxCount": 1
    },
    {
      "type": "objective",
      "number": 19,
      "question": "[AI 모델 튜닝] 다음 중 하이퍼파라미터 튜닝 기법에 해당하는 설명으로 옳지 않은 것은 무엇인가?",
      "choices": [
        "ㄱ",
        "ㄴ",
        "ㄷ",
        "ㄹ"
      ],
      "explanation": "<보기> \n ㄱ. Grid Search는 미리 정해진 하이퍼파라미터 조합 전체를 순차적으로 탐색하는 방식이다. \n ㄴ. Random Search는 전체 조합을 모두 평가하기 때문에 연산 효율은 떨어지지만, 항상 최적 성능을 보장한다. \n ㄷ. 베이지안 최적화는 이전 결과를 기반으로 다음 후보를 선택해 효율적인 탐색을 수행한다. \nㄹ. Hyperband는 early stopping을 결합하여 자원 낭비를 줄이고 빠른 튜닝을 가능하게 한다.",
      "textboxCount": 0
    },
    {
      "type": "objective",
      "number": 20,
      "question": "[AI 모델 튜닝] 딥러닝 모델의 하이퍼파라미터 중 학습률(learning rate)에 대한 설명으로 가장 적절한 것을 고르시오.",
      "choices": [
        "학습률이 너무 높으면 손실 함수의 지역 최솟값에 빠질 위험이 높아진다.",
        "학습률이 너무 낮으면 모델이 빠르게 수렴하고 과적합이 발생할 수 있다.",
        "학습률이 너무 높으면 손실 함수가 발산하거나 수렴하지 않을 수 있다.",
        "학습률은 일반적으로 고정된 값으로 설정하며, 학습 도중에 변경해서는 안 된다."
      ],
      "textboxCount": 0
    }

  
  {
    "type": "objective",
    "number": 21,
    "question": "다음 중 Blue/Green 배포 전략에 대한 설명으로 옳지 않은 것을 고르시오.",
    "choices": [
      "① 두 개의 독립된 환경을 번갈아 가며 트래픽을 전환하므로 롤백이 용이하다.",
      "② 새 버전(Blue)에서 장애가 발생해도 기존 버전(Green)은 중단 없이 서비스를 유지한다.",
      "③ 배포 시 두 환경이 동시에 외부 트래픽을 처리해 전체 처리량이 증가한다.",
      "④ 무중단(Zero-downtime) 배포를 지원하나, 두 환경을 동시에 운영해야 하므로 인프라 비용이 늘 수 있다.",
      "⑤ Blue 환경을 운영 중인 동안 Green 환경에서 안정성 테스트를 수행할 수 있다."
    ],
    "explanation": "정답: ③. Blue/Green 전략은 전환 시점에 하나의 환경만 외부 트래픽을 받도록 하므로 두 환경이 동시에 전체 트래픽을 처리하지 않는다.",
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 22,
    "question": "모델 서빙 아키텍처로 Serverless inference를 사용할 때 장점에 해당하지 않는 것은?",
    "choices": [
      "① 수요 변동에 따라 컴퓨팅 자원을 자동으로 스케일링한다.",
      "② 요청이 없으면 리소스를 할당하지 않아 비용이 절감될 수 있다.",
      "③ 장기 실행되는 상태 저장(Stateful) 추론에 최적화되어 있다.",
      "④ 관리형 플랫폼이 런타임 패치를 제공하므로 운영 부담이 줄어든다.",
      "⑤ 동시 요청이 급증해도 프로비저닝 지연을 최소화하도록 설계되었다."
    ],
    "explanation": "정답: ③. Serverless는 짧고 무상태(Stateless) 작업에 강점을 가지며, 상태 저장 장기 추론에는 적합하지 않다.",
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 23,
    "question": "다음 중 경량화 기법과 직접적인 관련이 가장 적은 조합을 고르시오.",
    "choices": [
      "① Depthwise Separable Convolution － 연산량 감소",
      "② Knowledge Distillation － 학생-교사 구조",
      "③ Label Smoothing － 매개변수 수 축소",
      "④ Quantization － 정수 연산 활용",
      "⑤ Structured Pruning － 채널 단위 가중치 제거"
    ],
    "explanation": "정답: ③. Label Smoothing은 출력 분포 평활화를 위한 정규화 기법으로 모델의 크기나 연산량을 줄이지 않는다.",
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 24,
    "question": "Retrieval-Augmented Generation (RAG) 파이프라인의 주요 구성 요소에 해당하지 않는 것은?",
    "choices": [
      "① 외부 지식베이스를 인덱싱하는 임베딩 파이프라인",
      "② 밀집 벡터 간 유사도 검색을 수행하는 Retriever",
      "③ 원문을 LLM 입력에 삽입하는 Context Assembler",
      "④ 생성 결과의 사실성을 검증하기 위한 Post-hoc Fact-Checker",
      "⑤ 사전 훈련 단계에서 매개변수 효율을 높이기 위한 LoRA Adaptor"
    ],
    "explanation": "정답: ⑤. LoRA Adaptor는 파라미터 효율적 미세조정 기술로 RAG 파이프라인의 핵심 모듈은 아니다.",
    "textboxCount": 0
  },
  {
    "type": "objective",
    "number": 25,
    "question": "멀티모달 LLM 학습 접근법 (가)와 (나)를 <보기>와 올바르게 짝지은 것을 고르시오.\n\n(가) Vision Encoder와 Text Decoder를 결합해 이미지→텍스트 생성 능력을 강조한다.\n(나) Cross-attention 레이어를 다중 모달 입력 사이에 삽입해 동시 추론을 수행한다.\n\n<보기>\nA. Autoregressive Image Captioning\nB. Contrastive Language-Image Pre-training(CLIP)\nC. Multimodal Fusion Transformer\nD. Diffusion-based Latent Blending",
    "choices": [
      "① (가)-A (나)-C",
      "② (가)-B (나)-A",
      "③ (가)-C (나)-B",
      "④ (가)-D (나)-A",
      "⑤ (가)-B (나)-D"
    ],
    "explanation": "정답: ①. (가)는 이미지 캡셔닝 기반 Autoregressive 방식(A), (나)는 Cross-attention을 활용한 Multimodal Fusion Transformer(C)에 해당한다.",
    "textboxCount": 0
  }



  ]